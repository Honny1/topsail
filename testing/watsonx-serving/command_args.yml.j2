{% set secrets_location = false | or_env(secrets.dir.env_key) %}
{% if not secrets_location %}
  {{ ("ERROR: secrets_location must be defined (secrets.dir.name="+ secrets.dir.name|string +" or env(secrets.dir.env_key=" + secrets.dir.env_key|string + ")) ") | raise_exception }}
{% endif %}
{% set s3_ldap_password_location = secrets_location + "/" + secrets.s3_ldap_password_file %}

# ---

sutest/cluster set_scale:
  name: {{ clusters.sutest.compute.machineset.name }}
  instance_type: {{ clusters.sutest.compute.machineset.type }}
{% if clusters.sutest.compute.dedicated %}
  taint: {{ clusters.sutest.compute.machineset.taint.key }}={{ clusters.sutest.compute.machineset.taint.value }}:{{ clusters.sutest.compute.machineset.taint.effect }}
{% endif %}
  disk_size: {{ clusters.sutest.compute.machineset.disk_size }}
  scale: SET_AT_RUNTIME

#
# Scale test - deploy RHODS
#

rhods deploy_ods:
  catalog_image: {{ rhods.catalog.image }}
  tag: {{ rhods.catalog.tag }}
  channel: {{ rhods.catalog.channel }}
  version: {{ rhods.catalog.version }}

#
# Scale test - Run one
#

sutest/cluster set_project_annotation/scale_test_node_selector:
  key: openshift.io/node-selector
  value: "{{ clusters.sutest.compute.machineset.taint.key }}={{ clusters.sutest.compute.machineset.taint.value }}"

sutest/cluster set_project_annotation/scale_test_toleration:
  key: scheduler.alpha.kubernetes.io/defaultTolerations
  value: '[{\"operator\": \"Exists\", \"effect\": \"{{ clusters.sutest.compute.machineset.taint.effect }}\", \"key\": \"{{ clusters.sutest.compute.machineset.taint.key }}\"}]'

#
# Scale test - Prepare Watsonx-Serving
#

sutest/cluster preload_image/watsonx-serving-runtime:
  namespace: {{ tests.scale.namespace.name }}
  name: caikit-image
  image: {{ watsonx_serving.model.serving_runtime.image }}

  node_selector_key: {{ clusters.sutest.compute.machineset.taint.key }}
  node_selector_value: "{{ clusters.sutest.compute.machineset.taint.value }}"
  pod_toleration_effect: {{ clusters.sutest.compute.machineset.taint.effect }}
  pod_toleration_key: {{ clusters.sutest.compute.machineset.taint.key }}

#
# Scale Test - Prepare GPU
#

gpu_operator enable_time_sharing:
  replicas: {{ gpu.time_sharing.replicas }}

#
# Scale test - Prepare User Pods
#

driver/cluster set_scale:
  instance_type: {{ clusters.driver.compute.machineset.type }}
  name: {{ clusters.driver.compute.machineset.name }}
{% if clusters.driver.compute.dedicated %}
  taint: {{ clusters.driver.compute.machineset.taint.key }}={{ clusters.driver.compute.machineset.taint.value }}:{{ clusters.driver.compute.machineset.taint.effect }}
{% endif %}
  scale: SET_AT_RUNTIME

driver/cluster set_project_annotation/test_node_selector:
  key: openshift.io/node-selector
  value: "{{ clusters.driver.compute.machineset.taint.key }}={{ clusters.driver.compute.machineset.taint.value }}"
  project: {{ base_image.namespace }}

driver/cluster set_project_annotation/test_toleration:
  key: scheduler.alpha.kubernetes.io/defaultTolerations
  value: '[{\"operator\": \"Exists\", \"effect\": \"{{ clusters.driver.compute.machineset.taint.effect }}\", \"key\": \"{{ clusters.driver.compute.machineset.taint.key }}\"}]'
  project: {{ base_image.namespace }}

base_image/utils build_push_image:
  namespace: "{{ base_image.namespace }}"
  image_local_name: "{{ base_image.imagestream }}"
  tag: "{{ base_image.repo.tag }}"
  _istag: "{{ base_image.imagestream }}:{{ base_image.repo.tag }}"

  git_repo: "{{ base_image.repo.url }}"
  git_ref: "{{ base_image.repo.ref }}" # may be overwritten at runtime with the PR ref
  dockerfile_path: "{{ base_image.repo.dockerfile_path }}"

extended_image/utils build_push_image:
  namespace: "{{ base_image.namespace }}"
  image_local_name: "{{ base_image.imagestream }}"
  tag: "{{ base_image.extend.tag }}"
  _istag: "{{ base_image.imagestream }}:{{ base_image.extend.tag }}"

  dockerfile_path: "{{ base_image.extend.local_dockerfile_path }}"
  from_imagetag: "{{ base_image.imagestream }}:{{ base_image.repo.tag }}"

cluster deploy_redis_server:
{% set redis_internal_address = "redis."+base_image.namespace+".svc" %}
  namespace: "{{ base_image.namespace }}"

cluster deploy_minio_s3_server:
  namespace: "{{ base_image.namespace }}"
  secret_properties_file: {{ s3_ldap_password_location }}
  bucket_name: {{ base_image.minio.bucket_name }}

#
# Test WatsonX Serving scale
#

local_ci run_multi/scale:
  user_count: "{{ tests.scale.namespace.replicas }}"
  namespace: "{{ base_image.namespace }}"
  istag: "{{ base_image.imagestream }}:{{ base_image.extend.tag }}"
  service_account: "{{ base_image.user.service_account }}"
  state_signal_redis_server: {{ redis_internal_address }}

  secret_name: "{{ secrets.dir.name }}"
  secret_env_key: "{{ secrets.dir.env_key }}"

  ci_command: "watsonx-serving test run_one"

  retrieve_artifacts: true
  minio_bucket_name: "{{ base_image.minio.bucket_name }}"
  minio_namespace: "{{ base_image.namespace }}"
  minio_secret_key_key: s3_ldap.passwords

  sleep_factor: {{ tests.scale.sleep_factor }}
  user_batch_size: 1

  git_pull: null #refs/pull/716/merge
  capture_prom_db: "{{ tests.capture_prom }}"

{% if tests.mode == "scale" and tests.scale.model.consolidated %}

#
# Test WatsonX Serving scale: run one
#

watsonx_serving deploy_model:
  namespace: {{ tests.scale.namespace.name }}
  sa_name: {{ watsonx_serving.sa_name }}

  model_id: {{ tests.scale.model.id }}
  model_name: {{ tests.scale.model.full_name }}

  serving_runtime_name: {{ tests.scale.model.name }}
  serving_runtime_image: {{ watsonx_serving.model.serving_runtime.image }}

  serving_runtime_resource_request: {{ tests.scale.model.serving_runtime.resource_request }}

  inference_service_name: {{ tests.scale.model.name }}
  storage_uri: {{ tests.scale.model.inference_service.storage_uri }}

watsonx_serving validate_model:
  namespace: {{ tests.scale.namespace.name }}
  inference_service_names: [{{ tests.scale.model.name }}]

  model_id: {{ tests.scale.model.id }}
  query_data: {{ tests.scale.model.inference_service.query_data }}
{% endif %}

#
# Test WatsonX Serving e2e
#
__e2e_aliases:
  local_ci_run_multi_e2e_common: &local_ci_run_multi_e2e
    namespace: "{{ base_image.namespace }}"
    istag: "{{ base_image.imagestream }}:{{ base_image.extend.tag }}"
    service_account: "{{ base_image.user.service_account }}"
    state_signal_redis_server: {{ redis_internal_address }}

    secret_name: "{{ secrets.dir.name }}"
    secret_env_key: "{{ secrets.dir.env_key }}"
    user_count: "{{ tests.e2e.models | length }}"

    retrieve_artifacts: true
    minio_bucket_name: "{{ base_image.minio.bucket_name }}"
    minio_namespace: "{{ base_image.namespace }}"
    minio_secret_key_key: s3_ldap.passwords

    user_batch_size: 1
    capture_prom_db: {{ tests.capture_prom }}
    git_pull: null #refs/pull/716/merge

local_ci run_multi/deploy_concurrently:
  <<: *local_ci_run_multi_e2e
  ci_command: "watsonx-serving test_e2e deploy_one_model --use-job-index"
  sleep_factor: 0


local_ci run_multi/test_sequentially:
  <<: *local_ci_run_multi_e2e
  ci_command: "watsonx-serving test_e2e test_models_sequentially"
  sleep_factor: 0
  user_count: 1


local_ci run_multi/test_concurrently:
  <<: *local_ci_run_multi_e2e
  ci_command: "watsonx-serving test_e2e test_one_model --use-job-index"
  sleep_factor: 0
