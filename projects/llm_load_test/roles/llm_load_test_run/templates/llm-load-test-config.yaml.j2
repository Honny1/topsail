output:
  format: "json"
  dir: "{{ artifact_extra_logs_dir }}/output"
  file: "output.json"
warmup: false
storage:
  type: local
dataset:
  file: "datasets/openorca_large_subset_010.jsonl"
  max_queries: 3000
  max_input_tokens: 1024
  max_output_tokens: 512
load_options:
  type: constant #Future options: loadgen, stair-step
  concurrency: {{ llm_load_test_run_concurrency }}
  duration: "{{ llm_load_test_run_duration }}"
plugin: "caikit_client_plugin"
plugin_options:
  interface: "grpc"
  streaming: True
  model_name: "{{ llm_load_test_run_model_id }}"
  route: "{{ llm_load_test_run_host}}"
extra_metadata:
  replicas: 1
