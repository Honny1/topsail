---
- name: Get the name of the current project
  command:
    oc project --short
  register: project_name_cmd
  when: not pipelines_capture_state_namespace

- name: Define the test environment
  set_fact:
    namespace: "{% if pipelines_capture_state_namespace | length > 0 %}{{ pipelines_capture_state_namespace }}{% else %}{{ project_name_cmd.stdout }}{% endif %}"
    user_id: "{{ pipelines_capture_state_user_id }}"

- name: Compute the DSP application name
  shell:
    set -o pipefail;
    oc get dspa -oname -n "{{ namespace }}" | head -1 | cut -d/ -f2
  register: dspa_name_cmd
  when: not pipelines_capture_state_dsp_application_name
  failed_when: not dspa_name_cmd.stdout

- name: Save the DSP application name
  set_fact:
    dspa_application_name: "{% if pipelines_capture_state_dsp_application_name %}{{ pipelines_capture_state_dsp_application_name }}{% else %}{{ dspa_name_cmd.stdout }}{% endif %}"

- name: Save the state of all the resources
  shell:
    oc get all -lapp=ds-pipeline-{{ dspa_application_name }} -n "{{ namespace }}"
       > "{{ artifact_extra_logs_dir }}/all.status"
  ignore_errors: true

- name: Get the status of the events
  shell:
    oc get events
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/events.status"
  ignore_errors: true

- name: Get the json definition of the events
  shell:
    oc get events -ojson
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/events.json"

- name: Save the workflow status
  shell:
    oc get workflow.argoproj.io -n "{{ namespace }}" > "{{ artifact_extra_logs_dir }}/workflow.status"
  ignore_errors: true

- name: Save the pipeline description
  shell:
    oc describe workflow.argoproj.io -n "{{ namespace }}" > "{{ artifact_extra_logs_dir }}/workflow.desc"
  ignore_errors: true

- name: Save the pipeline definition
  shell:
    oc get -oyaml workflow.argoproj.io -n "{{ namespace }}" > "{{ artifact_extra_logs_dir }}/workflow.yaml"
  ignore_errors: true

- name: Save the pipeline JSON definition
  shell:
    set -o pipefail;
    oc get -ojson workflow.argoproj.io -n "{{ namespace }}"
      | jq '[[.items[] | select(.metadata.annotations."pipelines.kubeflow.org/run_name"|contains("user{{ user_id }}-"))]] | {"apiVersion"{{ ":" }} "v1", "items"{{ ":" }} add}'
      > "{{ artifact_extra_logs_dir }}/workflow.json"
  ignore_errors: true

- name: Save the deployments definition
  shell:
    oc get -ojson deployments -n "{{ namespace }}" > "{{ artifact_extra_logs_dir }}/deployments.json"

- name: Save the status of the pods
  shell:
    oc get pods -owide
       -n "{{ namespace }}"
       > "{{ artifact_extra_logs_dir }}/pods.status"
  register: dspa_pod_names_cmd

- name: Get the names of the pods
  command:
    oc get pods
       -n "{{ namespace }}"
       -ojsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'
  register: dspa_pod_names_cmd

- name: Create the pods directory
  file:
    path: "{{ artifact_extra_logs_dir }}/pods"
    state: directory
    mode: '0755'

- name: Capture the logs of the pods
  loop: "{{ dspa_pod_names_cmd.stdout_lines }}"
  shell:
    oc logs pod/{{ item }}
       -n {{ namespace }}
       --all-containers --prefix
       > "{{ artifact_extra_logs_dir }}/pods/{{ item }}.log"
  ignore_errors: true

- name: Capture the description of the application pods
  loop: "{{ dspa_pod_names_cmd.stdout_lines }}"
  shell:
    oc describe pod/{{ item }}
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/pods/{{ item }}.desc"
  ignore_errors: true

- name: Capture the yaml definition of the pods
  loop: "{{ dspa_pod_names_cmd.stdout_lines }}"
  shell:
    oc get pod/{{ item }}
       -n {{ namespace }}
       -oyaml
       > "{{ artifact_extra_logs_dir }}/pods/{{ item }}.yaml"
  ignore_errors: true

- name: Capture the json definition of the pods
  loop: "{{ dspa_pod_names_cmd.stdout_lines }}"
  shell:
    oc get pod/{{ item }}
       -n {{ namespace }}
       -ojson
       > "{{ artifact_extra_logs_dir }}/pods/{{ item }}.json"
  ignore_errors: true

- name: Capture the DSP Application
  shell:
    oc get -oyaml dspa/{{ dspa_application_name }}
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/application.yaml"
  ignore_errors: true

- name: Capture the DSP Applications
  shell:
    oc get -ojson dspa
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/applications.json"
  ignore_errors: true

- name: Capture the Notebooks description
  shell:
    oc describe notebooks
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/notebooks.descr"
  ignore_errors: true

- name: Get the status of the notebook resources
  shell:
    oc get notebooks
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/notebooks.status"
  ignore_errors: true

- name: Get the definition of the notebook resources
  shell:
    oc get notebooks -oyaml
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/notebooks.yaml"
  ignore_errors: true

- name: Get the json definition of the notebook resources
  shell:
    oc get notebooks -ojson
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/notebooks.json"
  ignore_errors: true

- name: Get the json definition of the notebook resources
  shell:
    oc get notebooks -ojson
       -n {{ namespace }}
       > "{{ artifact_extra_logs_dir }}/notebooks.json"

- name: Dump the content of the DSPApplication database
  shell:
    oc rsh -n {{ namespace }}
       deploy/mariadb-{{ dspa_application_name }}
       mysqldump -u root mlpipeline > "{{ artifact_extra_logs_dir }}/database.sql"
