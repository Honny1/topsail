---
- name: Create the source directory
  file:
    path: "{{ artifact_extra_logs_dir }}/src"
    state: directory
    mode: '0755'

- name: Create the artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/artifacts"
    state: directory
    mode: '0755'

- name: Define versions and properties
  set_fact:
    clusterctl_version: v1.5.1
    capi_kubemark_version: v0.6.0
    capi_operator_version: main
    kubemark_worker_machine_count: 4
    capi_namespace: openshift-cluster-api

- name: Get the name of the cluster
  command:
    oc get infrastructure cluster -o jsonpath="{.status.infrastructureName}"
  register: cluster_name_cmd

- name: Get the K9s version of the cluster
  shell:
    set -o pipefail;
    oc version -ojson | jq -r .serverVersion.gitVersion | cut -d+ -f1 | cut -b2-
  register: k8s_version_cmd

- name: Save the cluster name
  set_fact:
    cluster_name: "{{ cluster_name_cmd.stdout }}"
    k8s_version: "{{ k8s_version_cmd.stdout }}"

# ---

- name: Enable TechPreview
  shell:
    set -o pipefail;
    oc get FeatureGate/cluster -ojson
       | jq '.spec.featureSet = "TechPreviewNoUpgrade"'
       | tee {{ artifact_extra_logs_dir }}/artifacts/tpnu.json
       | oc apply -f-

- name: Wait for the nodes to be upgraded
  shell:
    set -o pipefail;
    oc get mcp -ojsonpath='{range .items[*]}{.metadata.name}{" ="}{.status.unavailableMachineCount}{"=\n"}{end}' | grep -v "=0="
  register: has_unavailable_machines
  until: not has_unavailable_machines.rc != 1
  failed_when: has_unavailable_machines.rc != 1
  retries: 90
  delay: 30

- name: Wait for TPNU to create the openshift-cluster-api namespace
  shell:
    oc get ns openshift-cluster-api -oname 2>/dev/null
  register: has_namespace_cmd
  until: has_namespace_cmd.rc == 0
  retries: 90
  delay: 10

- name: Wait for the coreprovider CRD to appear
  command:
    oc get crd/coreproviders.operator.cluster.x-k8s.io
       -oname
       --ignore-not-found
  register: has_crd_cmd
  until: has_crd_cmd.stdout | length > 0
  retries: 60
  delay: 20

- name: Wait for the cluster-api to be installed
  shell:
    oc get coreprovider/cluster-api
       -n {{ capi_namespace }}
       -ojsonpath={.status.installedVersion}
       --ignore-not-found
  register: has_cluster_api_cmd
  until: has_cluster_api_cmd.stdout | length > 0
  retries: 30
  delay: 10

- name: Wait for the aws provider to be installed
  shell:
    oc get infrastructureproviders/aws
    -n {{ capi_namespace }}
    -ojsonpath={.status.installedVersion}
    --ignore-not-found
  register: has_aws_api_cmd
  until: has_aws_api_cmd.stdout | length > 0
  retries: 30
  delay: 10

# ---

- name: Install clusterctl
  shell: |
    curl -sSf --silent -L https://github.com/kubernetes-sigs/cluster-api/releases/download/{{ clusterctl_version }}/clusterctl-linux-amd64 -o /tmp/clusterctl
    chmod +x /tmp/clusterctl

- name: Prepare the config file
  shell: |
    cat <<EOF > {{ artifact_extra_logs_dir }}/clusterctl.yaml
    providers:
    - name: "kubemark"
      url: "https://github.com/kubernetes-sigs/cluster-api-provider-kubemark/releases/{{ capi_kubemark_version }}/infrastructure-components.yaml"
      type: "InfrastructureProvider"
    EOF

- name: Initialize kubemark provider
  shell:
    /tmp/clusterctl init
       --target-namespace {{ capi_namespace }}
       --infrastructure kubemark
       --bootstrap kubeadm
       --control-plane kubeadm
       --config {{ artifact_extra_logs_dir }}/clusterctl.yaml

# ---

# Beginning of the work arounds

# Workaround
- name: Apply the workarounds (controller dying because of OOM)
  shell: |
    oc set resources deploy/capk-controller-manager --limits="cpu=0.5,memory=200Mi" -n {{ capi_namespace }}

- name: Apply the workarounds (Pods not starting because of missing privileges)
  shell: |
    oc adm policy add-scc-to-user privileged -z capi-kubeadm-bootstrap-manager -n {{ capi_namespace }}
    oc adm policy add-scc-to-user privileged -z capi-kubeadm-control-plane-manager -n {{ capi_namespace }}

    oc delete replicaset --all -n {{ capi_namespace }}

# ---

# workaround (invalid AWS credentials)
- name: Wait for the capAWS secret to be created
  shell:
    oc get secret capa-manager-bootstrap-credentials
       -oname
       -n {{ capi_namespace }}
  register: has_secret_cmd
  until: has_secret_cmd.rc == 0
  retries: 60
  delay: 10

- name: Create the capAWS secret
  shell:
    set -o pipefail;
    set -e

    AWS_CREDS_FILE=$PSAP_ODS_SECRET_PATH/.awscred;
    key_id=$(cat "$AWS_CREDS_FILE" | grep aws_access_key_id | head -1 | cut -d" " -f3-);
    access_key=$(cat "$AWS_CREDS_FILE" | grep aws_secret_access_key | head -1 | cut -d" " -f3-);
    oc create secret generic capa-manager-bootstrap-credentials
       --from-file=credentials="$AWS_CREDS_FILE"
       --from-literal=aws_access_key_id="$key_id"
       --from-literal=aws_secret_access_key="$access_key"
       -n "{{ capi_namespace }}"
       -oyaml
       --dry-run=client
     | oc replace -f-

# ---
- name: Create the CAPI AWSCluster
  shell: |
    set -o pipefail;
    set -e

    AWS_REGION=$(oc get machineset.machine.openshift.io -n openshift-machine-api -o jsonpath="{.items[0].spec.template.spec.providerSpec.value.placement.region}")

    cat <<EOF | tee "{{ artifact_extra_logs_dir }}/src/capi_aws_cluster.yaml" | oc apply -f-
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: AWSCluster
    metadata:
      name: {{ cluster_name }}
      namespace: {{ capi_namespace }}
    spec:
      region: ${AWS_REGION}
    EOF


- name: Get the CAPI Core cluster template
  shell: |
    cat <<EOF | tee "{{ artifact_extra_logs_dir }}/src/capi_core_cluster.yaml" | oc apply -f-
    apiVersion: cluster.x-k8s.io/v1beta1
    kind: Cluster
    metadata:
      name: {{ cluster_name }}
      namespace: {{ capi_namespace }}
    spec:
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: AWSCluster
        name: {{ cluster_name }}
        namespace: {{ capi_namespace }}
    EOF

# ---

- name: Create the kubemark cluster resources
  shell:
    set -o pipefail;

    /tmp/clusterctl generate cluster "{{ cluster_name }}"
        --infrastructure kubemark
        --kubernetes-version {{ k8s_version }}
        --worker-machine-count={{kubemark_worker_machine_count}}
        --config {{ artifact_extra_logs_dir }}/clusterctl.yaml
      | yq -Y '.metadata.namespace = "{{ capi_namespace }}"'
      | tee "{{ artifact_extra_logs_dir }}/src/kubemark_cluster.yaml"
      | oc apply -f-

# ---

- name: Wait for the AWCluster to turn ready
  command:
    oc get awscluster/"{{ cluster_name }}"
       -n {{ capi_namespace }}
       -ojsonpath={.status.ready}
  register: aws_cluster_ready_cmd
  until: aws_cluster_ready_cmd.stdout == "true"
  retries: 30
  delay: 20

# ---


- name: Capture the state of the cluster
  shell:
    set -e

    /tmp/clusterctl describe cluster "{{ cluster_name }}"
        --config {{ artifact_extra_logs_dir }}/clusterctl.yaml
        -n {{ capi_namespace }}
        > "{{ artifact_extra_logs_dir }}/cluster.desc";

    oc get cluster/"{{ cluster_name }}"
       -oyaml
       -n {{ capi_namespace }}
       > "{{ artifact_extra_logs_dir }}/cluster.yaml";

    oc get machinedeployments.cluster.x-k8s.io
       -oyaml
       -n {{ capi_namespace }}
       > "{{ artifact_extra_logs_dir }}/machinedeployments.yaml";

- name: Capture the state of the pods
  shell:
    oc get pods
       -n {{ capi_namespace }}
       > "{{ artifact_extra_logs_dir }}/capi_pods.status"
